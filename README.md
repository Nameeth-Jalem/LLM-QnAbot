## LLM ChatBot using Gemini Pro
<div align="center">
  <img src="https://avatars.githubusercontent.com/Nameeth-Jalem" width="100" alt="Owner Avatar" />
  <h1>🤖 LLM-QnAbot</h1>
  <p><strong>Ask anything. Answer everything. Powered by Gemini Pro.</strong></p>

  <p>
    <a href="https://github.com/Nameeth-Jalem/LLM-QnAbot/stargazers"><img src="https://img.shields.io/github/stars/Nameeth-Jalem/LLM-QnAbot?style=social" alt="Stars"></a>
    <a href="https://github.com/Nameeth-Jalem/LLM-QnAbot/issues"><img src="https://img.shields.io/github/issues/Nameeth-Jalem/LLM-QnAbot" alt="Issues"></a>
    <a href="https://github.com/Nameeth-Jalem/LLM-QnAbot/network/members"><img src="https://img.shields.io/github/forks/Nameeth-Jalem/LLM-QnAbot" alt="Forks"></a>
    <a href="https://github.com/Nameeth-Jalem/LLM-QnAbot/blob/main/LICENSE"><img src="https://img.shields.io/github/license/Nameeth-Jalem/LLM-QnAbot" alt="License"></a>
  </p>

  <img src="https://img.shields.io/badge/Gemini%20Pro-LLM-blueviolet" />
  <img src="https://img.shields.io/badge/Python-3.10+-blue" />
  <img src="https://img.shields.io/badge/Status-Active-brightgreen" />

</div>

---

## ✨ Features

- 💬 **Interactive Chat Interface** using Gemini Pro LLM
- ⚙️ **Backend** built with lightweight `Flask`
- 📂 Supports **contextual QnA** using notebook ingestion
- 📊 **100% local** — no data sent externally
- 🔥 Ready-to-run with `app.py` or `llm.ipynb`

---

## 📦 Installation

```bash
git clone https://github.com/Nameeth-Jalem/LLM-QnAbot.git
cd LLM-QnAbot
pip install -r requirements.txt
